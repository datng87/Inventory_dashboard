{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find r0695 file in directory\n",
    "keyword = 'R0695'\n",
    "for fname in os.listdir('import_data'):\n",
    "    if keyword in fname:\n",
    "        filename = fname\n",
    "\n",
    "#extract the dateof the file\n",
    "date_list = filename [6:len(filename)-4].split('_')\n",
    "r0695_date=date_list[0] + '-' + date_list [1] + '-' + date_list [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  app.launch_new_instance()\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\pandas\\core\\frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\pandas\\core\\frame.py:5182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>VendorCode</th>\n",
       "      <th>VendorName</th>\n",
       "      <th>SOH</th>\n",
       "      <th>CostPerUnit</th>\n",
       "      <th>ItemGroup</th>\n",
       "      <th>CoverageGroup</th>\n",
       "      <th>Brand</th>\n",
       "      <th>BuyerCode</th>\n",
       "      <th>SuperGrpDesc</th>\n",
       "      <th>AvgMthUsage</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001/T1012KITCP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2245</td>\n",
       "      <td>FG_MAN</td>\n",
       "      <td>MTO</td>\n",
       "      <td>LOCKWOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>70 - 70 Mechanical Keying</td>\n",
       "      <td>0</td>\n",
       "      <td>15-06-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001/T1012KITSC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9497</td>\n",
       "      <td>FG_MAN</td>\n",
       "      <td>MTO</td>\n",
       "      <td>LOCKWOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>70 - 70 Mechanical Keying</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15-06-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001/T1023KITSC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9520</td>\n",
       "      <td>FG_MAN</td>\n",
       "      <td>MTO</td>\n",
       "      <td>LOCKWOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>70 - 70 Mechanical Keying</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15-06-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001/T1024KITSC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9520</td>\n",
       "      <td>FG_MAN</td>\n",
       "      <td>MTO</td>\n",
       "      <td>LOCKWOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>70 - 70 Mechanical Keying</td>\n",
       "      <td>0</td>\n",
       "      <td>15-06-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001/T1034KITSC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9520</td>\n",
       "      <td>FG_MAN</td>\n",
       "      <td>MTO</td>\n",
       "      <td>LOCKWOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>70 - 70 Mechanical Keying</td>\n",
       "      <td>1.67</td>\n",
       "      <td>15-06-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257900</th>\n",
       "      <td>ZT692-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>COM_MAN</td>\n",
       "      <td>PHANTOM</td>\n",
       "      <td>NONSALES</td>\n",
       "      <td>0</td>\n",
       "      <td>99 - 99 Non Sales Reporting Group</td>\n",
       "      <td>0</td>\n",
       "      <td>06-07-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257901</th>\n",
       "      <td>ZT811-70</td>\n",
       "      <td>71227</td>\n",
       "      <td>Diecast Australia Pty Ltd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>COM_PUREXT</td>\n",
       "      <td>PTS_RM_WK</td>\n",
       "      <td>NONSALES</td>\n",
       "      <td>L3</td>\n",
       "      <td>99 - 99 Non Sales Reporting Group</td>\n",
       "      <td>0</td>\n",
       "      <td>06-07-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257902</th>\n",
       "      <td>ZT8474-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8458</td>\n",
       "      <td>COM_MAN</td>\n",
       "      <td>PHANTOM</td>\n",
       "      <td>NONSALES</td>\n",
       "      <td>0</td>\n",
       "      <td>99 - 99 Non Sales Reporting Group</td>\n",
       "      <td>0</td>\n",
       "      <td>06-07-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257903</th>\n",
       "      <td>ZZ51081001</td>\n",
       "      <td>31773</td>\n",
       "      <td>Hempel (Wattyl) Australia Pty Ltd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Consumable</td>\n",
       "      <td>UNPLANNED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99 - 99 Non Sales Reporting Group</td>\n",
       "      <td>0</td>\n",
       "      <td>06-07-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257904</th>\n",
       "      <td>ZZ51201023</td>\n",
       "      <td>31882</td>\n",
       "      <td>Atotech Australia Pty Ltd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Consumable</td>\n",
       "      <td>UNPLANNED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99 - 99 Non Sales Reporting Group</td>\n",
       "      <td>0</td>\n",
       "      <td>06-07-2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257905 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ItemId  VendorCode                         VendorName  SOH  \\\n",
       "0       001/T1012KITCP           0                                  0  0.0   \n",
       "1       001/T1012KITSC           0                                  0  0.0   \n",
       "2       001/T1023KITSC           0                                  0  0.0   \n",
       "3       001/T1024KITSC           0                                  0  0.0   \n",
       "4       001/T1034KITSC           0                                  0  0.0   \n",
       "...                ...         ...                                ...  ...   \n",
       "257900        ZT692-15           0                                  0  0.0   \n",
       "257901        ZT811-70       71227          Diecast Australia Pty Ltd  0.0   \n",
       "257902       ZT8474-20           0                                  0  0.0   \n",
       "257903      ZZ51081001       31773  Hempel (Wattyl) Australia Pty Ltd  0.0   \n",
       "257904      ZZ51201023       31882          Atotech Australia Pty Ltd  0.0   \n",
       "\n",
       "        CostPerUnit   ItemGroup CoverageGroup     Brand BuyerCode  \\\n",
       "0           13.2245      FG_MAN           MTO  LOCKWOOD         0   \n",
       "1           11.9497      FG_MAN           MTO  LOCKWOOD         0   \n",
       "2           11.9520      FG_MAN           MTO  LOCKWOOD         0   \n",
       "3           11.9520      FG_MAN           MTO  LOCKWOOD         0   \n",
       "4           11.9520      FG_MAN           MTO  LOCKWOOD         0   \n",
       "...             ...         ...           ...       ...       ...   \n",
       "257900       0.3399     COM_MAN       PHANTOM  NONSALES         0   \n",
       "257901       0.7700  COM_PUREXT     PTS_RM_WK  NONSALES        L3   \n",
       "257902       0.8458     COM_MAN       PHANTOM  NONSALES         0   \n",
       "257903       0.0000  Consumable     UNPLANNED         0         0   \n",
       "257904       0.0000  Consumable     UNPLANNED         0         0   \n",
       "\n",
       "                             SuperGrpDesc AvgMthUsage        Date  \n",
       "0               70 - 70 Mechanical Keying           0  15-06-2022  \n",
       "1               70 - 70 Mechanical Keying        3.33  15-06-2022  \n",
       "2               70 - 70 Mechanical Keying        3.33  15-06-2022  \n",
       "3               70 - 70 Mechanical Keying           0  15-06-2022  \n",
       "4               70 - 70 Mechanical Keying        1.67  15-06-2022  \n",
       "...                                   ...         ...         ...  \n",
       "257900  99 - 99 Non Sales Reporting Group           0  06-07-2022  \n",
       "257901  99 - 99 Non Sales Reporting Group           0  06-07-2022  \n",
       "257902  99 - 99 Non Sales Reporting Group           0  06-07-2022  \n",
       "257903  99 - 99 Non Sales Reporting Group           0  06-07-2022  \n",
       "257904  99 - 99 Non Sales Reporting Group           0  06-07-2022  \n",
       "\n",
       "[257905 rows x 12 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read and clean up data R0695\n",
    "r0695 = pd.read_csv('import_data/' + filename)\n",
    "#save data to backup folder\n",
    "r0695.to_csv(f'backup_data/{filename}',index=False)\n",
    "r0695=r0695[['ItemId','VendorCode','VendorName','SOH','CostPerUnit','ItemGroup',\n",
    "       'CoverageGroup','Brand','BuyerCode','SuperGrpDesc','AvgMthUsage']]\n",
    "r0695.fillna('0',inplace=True)\n",
    "#convert vendor code to int64\n",
    "r0695['VendorCode'] = r0695['VendorCode'].astype('int64')\n",
    "\n",
    "r0695['SOH'] = r0695['SOH'].astype(str) #to be confirm\n",
    "r0695['CostPerUnit'] = r0695['CostPerUnit'].astype(str) #to be confirm\n",
    "\n",
    "#convert SOH and Costperunit to float\n",
    "r0695['SOH'] =r0695['SOH'].str.replace('(','-')\n",
    "r0695['SOH'] =r0695['SOH'].str.replace(')','')\n",
    "r0695['SOH'] = r0695['SOH'].str.replace(\",\",\"\").astype(float)\n",
    "r0695['CostPerUnit'] =r0695['CostPerUnit'].str.replace('(','-')\n",
    "r0695['CostPerUnit'] =r0695['CostPerUnit'].str.replace(')','')\n",
    "r0695['CostPerUnit'] = r0695['CostPerUnit'].str.replace(\",\",\"\").astype(float)\n",
    "#append date of data as String\n",
    "r0695['Date'] = r0695_date\n",
    "\n",
    "#open database, if not found file, generate data using r0695 data\n",
    "try:\n",
    "       dataset = pd.read_csv('archive/consolidate_data.csv')\n",
    "except FileNotFoundError:\n",
    "       dataset = r0695.copy()\n",
    "\n",
    "\n",
    "#check if the r0695 data has duplicate date\n",
    "duplicate_data = 0\n",
    "#get list of date in database\n",
    "dataset_date = dataset['Date'].unique().tolist()\n",
    "for i in dataset_date:\n",
    "       if r0695_date == i:\n",
    "              #set flag if the date of r0695 is duplicated\n",
    "              duplicate_data = 1  \n",
    "              break\n",
    "\n",
    "# if duplicate date found\n",
    "if duplicate_data ==1:\n",
    "       print('Duplicate value found')\n",
    "       answer = input ('Do you want to override? (Y/N) :')\n",
    "       if answer == 'Y':\n",
    "              #remove old data for the duplicate date and itemid\n",
    "              r0695_itemlist = r0695['ItemId'].tolist()\n",
    "              dataset = dataset[(dataset[\"Date\"]!=r0695_date) |  (~dataset['ItemId'].isin(r0695_itemlist)) ]    \n",
    "              #append new data\n",
    "              new_dataset = pd.concat([dataset,r0695],ignore_index=True)\n",
    "              new_dataset.to_csv('archive/consolidate_data.csv',index=False)\n",
    "       else:\n",
    "              new_dataset = pd.read_csv('archive/consolidate_data.csv')\n",
    "      \n",
    "# if no duplicate date found, append new data\n",
    "else:\n",
    "       new_dataset = pd.concat([dataset,r0695],ignore_index=True)\n",
    "       new_dataset.to_csv('archive/consolidate_data.csv',index=False)\n",
    "\n",
    "#delete r0695 file after copy data\n",
    "os.remove('import_data/'+filename)\n",
    "\n",
    "#update latest standard cost\n",
    "latest_std_cost = r0695[['ItemId','CostPerUnit','Date']]\n",
    "latest_std_cost.rename(columns={'CostPerUnit':'Std_cost_latest'},inplace=True)\n",
    "latest_std_cost.fillna(0,inplace=True)\n",
    "latest_std_cost.to_csv('archive/latest_std_cost.csv',index=False)\n",
    "\n",
    "new_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Std_cost_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001/T1012KITCP</td>\n",
       "      <td>13.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001/T1012KITSC</td>\n",
       "      <td>11.9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001/T1023KITSC</td>\n",
       "      <td>11.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001/T1024KITSC</td>\n",
       "      <td>11.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001/T1034KITSC</td>\n",
       "      <td>11.9520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ItemId  Std_cost_latest\n",
       "0  001/T1012KITCP          13.2245\n",
       "1  001/T1012KITSC          11.9497\n",
       "2  001/T1023KITSC          11.9520\n",
       "3  001/T1024KITSC          11.9520\n",
       "4  001/T1034KITSC          11.9520"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge latest data to database and calculate stock value\n",
    "new_dataset = pd.read_csv('archive/consolidate_data.csv')\n",
    "latest_std_cost = pd.read_csv('archive/latest_std_cost.csv')\n",
    "\n",
    "del latest_std_cost['Date']\n",
    "#append latest standard cost to database\n",
    "process_dataset=new_dataset.merge(latest_std_cost,on='ItemId',how='left')\n",
    "#check if any latest_std_cost is missing. If yes fill with original CostPerUnit data\n",
    "process_dataset['Std_cost_latest'].fillna(process_dataset['CostPerUnit'],inplace=True)\n",
    "#calculate stock value = soh * standard cost\n",
    "process_dataset ['Stock_value'] = process_dataset['SOH'] * process_dataset['Std_cost_latest']\n",
    "process_dataset['VendorCode'] =process_dataset['VendorCode'].astype('str')\n",
    "process_dataset['Vendor'] = process_dataset['VendorCode'] + ' - ' + process_dataset['VendorName']\n",
    "process_dataset['CoverageGroup1'] = process_dataset['ItemGroup']\n",
    "process_dataset['CoverageGroup1'].replace({'BYPROD':'Other','0':'Other','Consumable':'Other','EngUse':'Other','FacSup':'Other',\n",
    "                                           'FrghtChg':'Other','InstlChg':'Other','LabrChg':'Other','MOC':'Other','NBNInstal':'Other',\n",
    "                                           'SPECKEYCHG':'Other','TOOL':'Other','MK_STORE':'Other'},inplace=True)\n",
    "'''\n",
    "process_dataset['CoverageGroup1'].replace({'PTS_WK':'PUR_FG','PTS_2WK':'PUR_FG','PTS_MTH':'PUR_FG','PTS_3MTH':'PUR_FG',\n",
    "                                           'PTO_CUS':'PUR_FG','PTO_NAF':'PUR_FG',                                                                                                                           \n",
    "                                           'PTS_RM_WK':'PUR_RM','PTS_RM_2WK':'PUR_RM','PTS_RM_MTH':'PUR_RM','PTS_KANBAN':'PUR_RM',                                          \n",
    "                                           'PTO_RM_NAF':'PUR_RM',\n",
    "                                           'MTS':'MAN_FG','MTO':'MAN_FG','KANBAN':'MAN_FG','SPK':'MAN_FG','SPK_MTS':'MAN_FG',                                                                             \n",
    "                                           'PHANTOM':'Other','0':'Other','ROS':'Other'\n",
    "                                           },inplace=True)\n",
    "'''\n",
    "latest_std_cost.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate stock value by supplier and date\n",
    "\n",
    "category = 'Vendor'\n",
    "process_dataset.groupby([category,'Date']).sum()['Stock_value'].reset_index().to_csv('archive/supplier_stock_value.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category = 'Vendor'\n",
    "process_dataset.loc[process_dataset['ItemGroup'].isin(['FG_PURIG',\n",
    "                                                       'FG_PUREXT']),:].groupby([category,'Date']).sum()['Stock_value'].reset_index().to_csv('archive/supplier_stock_value_FG.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate by SuperGrpDesc\n",
    "category = 'SuperGrpDesc'\n",
    "process_dataset.groupby([category,'Date']).sum()['Stock_value'].reset_index().to_csv('archive/supergroup_stock_value.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate by item group\n",
    "category = 'ItemGroup'\n",
    "process_dataset.groupby([category,'Date']).sum()['Stock_value'].reset_index().to_csv('archive/itemgroup_stock_value.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate by coverage group\n",
    "\n",
    "category = 'CoverageGroup1'\n",
    "process_dataset.groupby([category,'Date']).sum()['Stock_value'].reset_index().to_csv('archive/coveragegroup_stock_value.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate summary\n",
    "\n",
    "process_dataset.groupby(['SuperGrpDesc','BuyerCode','CoverageGroup1','Vendor','Date']).sum()['Stock_value'].reset_index().to_csv('archive/summary_aggregate.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>VendorCode</th>\n",
       "      <th>VendorName</th>\n",
       "      <th>SOH</th>\n",
       "      <th>CostPerUnit</th>\n",
       "      <th>ItemGroup</th>\n",
       "      <th>CoverageGroup</th>\n",
       "      <th>Brand</th>\n",
       "      <th>BuyerCode</th>\n",
       "      <th>SuperGrpDesc</th>\n",
       "      <th>AvgMthUsage</th>\n",
       "      <th>Date</th>\n",
       "      <th>Std_cost_latest</th>\n",
       "      <th>Stock_value</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>CoverageGroup1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256146</th>\n",
       "      <td>W286217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.6949</td>\n",
       "      <td>FG_MAN</td>\n",
       "      <td>MTO</td>\n",
       "      <td>WHITCO</td>\n",
       "      <td>0</td>\n",
       "      <td>10 - 10 Window Lock/Access</td>\n",
       "      <td>41.67</td>\n",
       "      <td>06-07-2022</td>\n",
       "      <td>0.6949</td>\n",
       "      <td>625.41</td>\n",
       "      <td>0 - 0</td>\n",
       "      <td>FG_MAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ItemId VendorCode VendorName    SOH  CostPerUnit ItemGroup  \\\n",
       "256146  W286217          0          0  900.0       0.6949    FG_MAN   \n",
       "\n",
       "       CoverageGroup   Brand BuyerCode                SuperGrpDesc  \\\n",
       "256146           MTO  WHITCO         0  10 - 10 Window Lock/Access   \n",
       "\n",
       "       AvgMthUsage        Date  Std_cost_latest  Stock_value Vendor  \\\n",
       "256146       41.67  06-07-2022           0.6949       625.41  0 - 0   \n",
       "\n",
       "       CoverageGroup1  \n",
       "256146         FG_MAN  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggregate summary\n",
    "\n",
    "curdate_string = [r0695_date]\n",
    "#filter latest week data\n",
    "item_summary = process_dataset[process_dataset['Date'].isin(curdate_string)]\n",
    "item_summary.loc[item_summary.ItemId=='W286217',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (79,94,96,97,103,108,113,118,122,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  if sys.path[0] == '':\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  del sys.path[0]\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  app.launch_new_instance()\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:38: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Date</th>\n",
       "      <th>forecast_per_week_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001/T1012KITCP</td>\n",
       "      <td>06-07-2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001/T1012KITCP</td>\n",
       "      <td>13-07-2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001/T1012KITCP</td>\n",
       "      <td>20-07-2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001/T1012KITCP</td>\n",
       "      <td>27-07-2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001/T1012KITCP</td>\n",
       "      <td>03-08-2022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ItemId        Date  forecast_per_week_processed\n",
       "0  001/T1012KITCP  06-07-2022                          0.0\n",
       "1  001/T1012KITCP  13-07-2022                          0.0\n",
       "2  001/T1012KITCP  20-07-2022                          0.0\n",
       "3  001/T1012KITCP  27-07-2022                          0.0\n",
       "4  001/T1012KITCP  03-08-2022                          0.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load R0831\n",
    "forecast = pd.read_csv('import_data/R0831.csv',header=2)\n",
    "forecast = forecast[['ItemId1','Std_Cost',\n",
    "                         'FC_CUR1','Forecast_Current_plus_1','Forecast_Current_plus_2','Forecast_Current_plus_3','Forecast_Current_plus_4',\n",
    "                         'Forecast_Current_plus_5','Forecast_Current_plus_6','ReqGroupId1','Usage_3_Months']]\n",
    "#exclude PTO\n",
    "forecast = forecast.loc[(forecast['ReqGroupId1']!='PTO_CUS')&(forecast['ReqGroupId1']!='PTO_NAF')&(forecast['ReqGroupId1']!='PTO_RM_NAF'),:]\n",
    "forecast.rename(columns={'ItemId1':'ItemId'},inplace = True)\n",
    "\n",
    "forecast=forecast.fillna(0)\n",
    "forecast['Std_Cost'] = forecast['Std_Cost'].astype(str) #to be confirm\n",
    "forecast['Std_Cost']= forecast['Std_Cost'].str.replace('(','-')\n",
    "forecast['Std_Cost'] = forecast['Std_Cost'].str.replace(')','')\n",
    "forecast['Std_Cost'] =  forecast['Std_Cost'].str.replace(\",\",\"\").astype(float)\n",
    "forecast['FC_CUR1'] = forecast['FC_CUR1'].astype(str) #to be confirm\n",
    "forecast['FC_CUR1']= forecast['FC_CUR1'].str.replace('(','-')\n",
    "forecast['FC_CUR1'] = forecast['FC_CUR1'].str.replace(')','')\n",
    "forecast['FC_CUR1'] =  forecast['FC_CUR1'].str.replace(\",\",\"\").astype(float)\n",
    "forecast['Usage_3_Months'] = forecast['Usage_3_Months'].astype(str) #to be confirm\n",
    "forecast['Usage_3_Months']= forecast['Usage_3_Months'].str.replace('(','-')\n",
    "forecast['Usage_3_Months'] = forecast['Usage_3_Months'].str.replace(')','')\n",
    "forecast['Usage_3_Months'] =  forecast['Usage_3_Months'].str.replace(\",\",\"\").astype(float)\n",
    "forecast['curFC_cost'] = forecast.Std_Cost * forecast.FC_CUR1\n",
    "for i in range (1,7):\n",
    "    forecast[f'Forecast_Current_plus_{i}'] = forecast[f'Forecast_Current_plus_{i}'].astype(str) #to be confirm\n",
    "    forecast[f'Forecast_Current_plus_{i}']= forecast[f'Forecast_Current_plus_{i}'].str.replace('(','-')\n",
    "    forecast[f'Forecast_Current_plus_{i}'] = forecast[f'Forecast_Current_plus_{i}'].str.replace(')','')\n",
    "    forecast[f'Forecast_Current_plus_{i}'] =  forecast[f'Forecast_Current_plus_{i}'].str.replace(\",\",\"\").astype(float)\n",
    "    forecast[f'Forecast_Current_plus_{i}_cost'] = forecast.Std_Cost * forecast[f'Forecast_Current_plus_{i}']\n",
    "\n",
    "#added usage 3 month and forecast 3 month value to process_dataset\n",
    "forecast['Forecast_3_months'] = (forecast['Forecast_Current_plus_1']+ forecast['Forecast_Current_plus_2'] + forecast['Forecast_Current_plus_3'])/3\n",
    "forecast_temp = forecast.copy()\n",
    "forecast_temp = forecast_temp[['ItemId','Usage_3_Months','Forecast_3_months']]\n",
    "#calculate usage per month\n",
    "forecast_temp['Usage_3_Months']=forecast_temp['Usage_3_Months']/3\n",
    "process_dataset=process_dataset.merge(forecast_temp,on='ItemId',how='left')\n",
    "#fill with average mth usage if na\n",
    "process_dataset['AvgMthUsage'] = process_dataset['AvgMthUsage'].astype(str) #to be confirm\n",
    "process_dataset['AvgMthUsage']= process_dataset['AvgMthUsage'].str.replace('(','-')\n",
    "process_dataset['AvgMthUsage'] = process_dataset['AvgMthUsage'].str.replace(')','')\n",
    "process_dataset['AvgMthUsage'] =  process_dataset['AvgMthUsage'].str.replace(\",\",\"\").astype(float)\n",
    "process_dataset['Usage_3_Months'].fillna(process_dataset['AvgMthUsage'],inplace=True)\n",
    "process_dataset['Forecast_3_months'].fillna(process_dataset['AvgMthUsage'],inplace=True)\n",
    "process_dataset['Usage_3_Months_value']= process_dataset['Usage_3_Months'] * process_dataset['Std_cost_latest']\n",
    "process_dataset['Forecast_3_months_value']= process_dataset['Forecast_3_months'] * process_dataset['Std_cost_latest']\n",
    "del process_dataset['Usage_3_Months']\n",
    "del process_dataset['Forecast_3_months'] \n",
    "\n",
    "#create slow moving data copy\n",
    "slow_moving=forecast.copy()\n",
    "#aggregate total data\n",
    "\n",
    "forecast = forecast.groupby('ItemId').sum()[['curFC_cost','Forecast_Current_plus_1_cost','Forecast_Current_plus_2_cost','Forecast_Current_plus_3_cost',\n",
    "                                 'Forecast_Current_plus_4_cost']].reset_index()\n",
    "#normalize the dataframe                                 \n",
    "forecast_column = ['curFC_cost','Forecast_Current_plus_1_cost','Forecast_Current_plus_2_cost','Forecast_Current_plus_3_cost',\n",
    "                                 'Forecast_Current_plus_4_cost']\n",
    "forecast = forecast.melt(id_vars='ItemId',value_vars=forecast_column,var_name='forecast_period',value_name='forecast_cost')\n",
    "\n",
    "#create list of month curFC,CurFC+1... \n",
    "for i in range(3):\n",
    "    date_list[i] = int(date_list[i])\n",
    "month_list = [i if i<=12 else i-12 for i in range(date_list[1],date_list[1]+5)]\n",
    "#calculate remaining date for current month\n",
    "days_of_month_dict = [0,31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "remaining_days = days_of_month_dict[date_list[1]] - date_list[0]\n",
    "#calculate total weeks has forcast data\n",
    "total_weeks=remaining_days\n",
    "for i in range(1,5):\n",
    "    total_weeks += days_of_month_dict[month_list[i]]\n",
    "total_weeks = int(total_weeks/7)\n",
    "#replace forecast month by value\n",
    "forecast.replace(['curFC_cost','Forecast_Current_plus_1_cost','Forecast_Current_plus_2_cost',\n",
    "                  'Forecast_Current_plus_3_cost','Forecast_Current_plus_4_cost'],month_list,inplace=True)\n",
    "forecast.forecast_period=forecast.forecast_period.astype(int)\n",
    "#calculate forecast per week\n",
    "forecast['forecast_per_week'] = forecast.apply(lambda row: round(row['forecast_cost'] * 7/ days_of_month_dict[row['forecast_period']],1),axis=1)\n",
    "\n",
    "\n",
    "#create new forecsat data frame for each week\n",
    "item_list=item_summary.ItemId.unique()\n",
    "week_id = np.arange(0,total_weeks+1)\n",
    "#convert string to datetime\n",
    "curdate_datetime =datetime.strptime(r0695_date,'%d-%m-%Y')\n",
    "\n",
    "#create base df\n",
    "future_dates=[]\n",
    "for i in range(0,total_weeks+1):\n",
    "    future_dates.append (curdate_datetime+timedelta(days=7*i))\n",
    "week_id_df= pd.DataFrame({'week_id':week_id,\n",
    "                          'Date':future_dates})\n",
    "week_id_df['day_of_month'] = pd.DatetimeIndex(week_id_df['Date']).day\n",
    "week_id_df['forecast_period'] = pd.DatetimeIndex(week_id_df['Date']).month\n",
    "week_id_df['last_date_of_month'] = week_id_df.apply(lambda x: days_of_month_dict[x['forecast_period']],axis=1)\n",
    "week_id_df['days_to_end_of_month'] = week_id_df.last_date_of_month - week_id_df.day_of_month\n",
    "def week_order (x):\n",
    "    if x['days_to_end_of_month'] < 7:\n",
    "        return 'Last'\n",
    "    elif x['day_of_month'] <= 7:\n",
    "        return 'First'\n",
    "    else:\n",
    "        return 'Mid'\n",
    "week_id_df['week_order'] = week_id_df.apply(lambda x: week_order(x),axis=1)\n",
    "\n",
    "\n",
    "# add base df with each item and concat to new df\n",
    "def generate_vendor_df (df,item_list):\n",
    "    list_dfs = []\n",
    "    for i in item_list:\n",
    "        df1= pd.DataFrame.copy(df)\n",
    "        df1['ItemId']=i\n",
    "        list_dfs.append(df1)\n",
    "    return pd.concat(list_dfs)\n",
    "forecast_process = generate_vendor_df(week_id_df,item_list)\n",
    "\n",
    "#mege forecast data\n",
    "forecast_process=forecast_process.merge(forecast,how='left',on=['ItemId','forecast_period'])\n",
    "forecast_process.fillna(0,inplace=True)\n",
    "forecast_process['Date'] = forecast_process['Date'].dt.strftime('%d-%m-%Y')\n",
    "#calculate week forecast processed\n",
    "forecast_process['remaining_cost_of_month'] = forecast_process.apply(lambda x: x['forecast_per_week'] * x['days_to_end_of_month'] /7 \n",
    "                                                                     if ((x['days_to_end_of_month'] <7)&(x['days_to_end_of_month']>0)) else 0,axis=1)\n",
    "#calculate remaining_cost_previous_month with current date =0\n",
    "forecast_process['remaining_cost_previous_month'] = forecast_process.remaining_cost_of_month.shift(1)\n",
    "forecast_process.loc[forecast_process.Date == r0695_date, 'remaining_cost_previous_month']  = 0\n",
    "\n",
    "#current week = weekly forecast\n",
    "forecast_process['forecast_per_week_processed']=forecast_process.forecast_per_week\n",
    "#if first week: current week + last week\n",
    "forecast_process.loc[forecast_process.week_order == 'First',\n",
    "                     'forecast_per_week_processed'] = round(forecast_process.loc[forecast_process.week_order == 'First',\n",
    "                                                                           'forecast_per_week'] * forecast_process.loc[forecast_process.week_order == 'First', \n",
    "                                                                                                                       'day_of_month']/7 + forecast_process.loc[forecast_process.week_order == 'First',\n",
    "                                                                                                                                                                'remaining_cost_previous_month'],1)\n",
    "#first date =0\n",
    "forecast_process.loc[forecast_process.Date == r0695_date, 'forecast_per_week_processed']  = 0\n",
    "# take essential data\n",
    "forecast_process =forecast_process[['ItemId','Date','forecast_per_week_processed']]\n",
    "\n",
    "forecast_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Date</th>\n",
       "      <th>po_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-1K1BRNDP</td>\n",
       "      <td>20-07-2022</td>\n",
       "      <td>914.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-1K1BRNDP</td>\n",
       "      <td>03-08-2022</td>\n",
       "      <td>571.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-1K1BRNDP</td>\n",
       "      <td>10-08-2022</td>\n",
       "      <td>343.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-1K1BRNDP</td>\n",
       "      <td>07-09-2022</td>\n",
       "      <td>914.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-1K1CP</td>\n",
       "      <td>03-08-2022</td>\n",
       "      <td>1108.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ItemId        Date  po_cost\n",
       "0  001-1K1BRNDP  20-07-2022   914.88\n",
       "1  001-1K1BRNDP  03-08-2022   571.80\n",
       "2  001-1K1BRNDP  10-08-2022   343.08\n",
       "3  001-1K1BRNDP  07-09-2022   914.88\n",
       "4     001-1K1CP  03-08-2022  1108.80"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#process open pos data\n",
    "\n",
    "#check encoding\n",
    "#with open('import_data/Open_POs.csv') as f:\n",
    "#    print(f)\n",
    "\n",
    "# look at the first ten thousand bytes to guess the character encoding\n",
    "#with open(\"import_data/Open_POs.csv\", 'rb') as rawdata:\n",
    "#    result = chardet.detect(rawdata.read(10000))\n",
    "# check what the character encoding might be\n",
    "#print(result)\n",
    "\n",
    "open_po = pd.read_csv('import_data/Open_POs.csv',encoding='utf8')\n",
    "open_po = open_po[['Item number','Delivery date','Confirmed delivery date','Deliver remainder','Coverage group']]\n",
    "\n",
    "#exclude PTO\n",
    "open_po = open_po.loc[(open_po['Coverage group']!='PTO_CUS')&(open_po['Coverage group']!='PTO_NAF')&(open_po['Coverage group']!='PTO_RM_NAF'),:]\n",
    "#fill confirmed delivery date = delivery date if empty\n",
    "open_po['Confirmed delivery date'].fillna(open_po['Delivery date'],inplace=True)\n",
    "open_po.fillna(0,inplace=True)\n",
    "open_po['Deliver remainder'] = open_po['Deliver remainder'].astype(str) #to be confirm\n",
    "open_po['Deliver remainder']= open_po['Deliver remainder'].str.replace('(','-')\n",
    "open_po['Deliver remainder'] = open_po['Deliver remainder'].str.replace(')','')\n",
    "open_po['Deliver remainder'] =  open_po['Deliver remainder'].str.replace(\",\",\"\").astype(float)\n",
    "#rename column to merge\n",
    "open_po.rename(columns={'Item number':'ItemId'},inplace=True)\n",
    "#merge with standard cost data\n",
    "open_po=open_po.merge(latest_std_cost,on='ItemId',how='left') \n",
    "#calculate line item cost\n",
    "open_po['po_cost'] = open_po['Deliver remainder'] * open_po.Std_cost_latest\n",
    "open_po.fillna(0,inplace=True)\n",
    "\n",
    "#convert confirmed delivery date to datetime\n",
    "open_po['Confirmed delivery date'] = pd.to_datetime(open_po['Confirmed delivery date'],format='%d/%m/%Y')\n",
    "#bucket the confirmed delivery date to week\n",
    "#if confirmed delivery date <= before today +7 => today +7\n",
    "#round to next today +7, return None if outside forecast period\n",
    "def convert_po_date(df,future_dates_list):\n",
    "    for i in future_dates_list:\n",
    "        if df['Confirmed delivery date'] <= i:\n",
    "            return i       \n",
    "    return None\n",
    "open_po['Date'] = open_po.apply(lambda x: convert_po_date(x,future_dates[1:len(future_dates)]), axis = 1)\n",
    "#drop open PO outside forecast period\n",
    "open_po.dropna(inplace=True)\n",
    "#aggregate by vedor + new buket confirm delivery date\n",
    "open_po = open_po.groupby(['ItemId','Date']).sum()['po_cost'].reset_index()\n",
    "#convert date to string\n",
    "open_po['Date'] = open_po['Date'].dt.strftime('%d-%m-%Y')\n",
    "open_po.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Date</th>\n",
       "      <th>intake_cost</th>\n",
       "      <th>eoh_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62743</th>\n",
       "      <td>W286217</td>\n",
       "      <td>06-07-2022</td>\n",
       "      <td>625.41</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382105</th>\n",
       "      <td>W286217</td>\n",
       "      <td>13-07-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382106</th>\n",
       "      <td>W286217</td>\n",
       "      <td>20-07-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382107</th>\n",
       "      <td>W286217</td>\n",
       "      <td>27-07-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382108</th>\n",
       "      <td>W286217</td>\n",
       "      <td>03-08-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382109</th>\n",
       "      <td>W286217</td>\n",
       "      <td>10-08-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382110</th>\n",
       "      <td>W286217</td>\n",
       "      <td>17-08-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382111</th>\n",
       "      <td>W286217</td>\n",
       "      <td>24-08-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382112</th>\n",
       "      <td>W286217</td>\n",
       "      <td>31-08-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382113</th>\n",
       "      <td>W286217</td>\n",
       "      <td>07-09-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382114</th>\n",
       "      <td>W286217</td>\n",
       "      <td>14-09-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382115</th>\n",
       "      <td>W286217</td>\n",
       "      <td>21-09-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382116</th>\n",
       "      <td>W286217</td>\n",
       "      <td>28-09-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382117</th>\n",
       "      <td>W286217</td>\n",
       "      <td>05-10-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382118</th>\n",
       "      <td>W286217</td>\n",
       "      <td>12-10-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382119</th>\n",
       "      <td>W286217</td>\n",
       "      <td>19-10-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382120</th>\n",
       "      <td>W286217</td>\n",
       "      <td>26-10-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382121</th>\n",
       "      <td>W286217</td>\n",
       "      <td>02-11-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382122</th>\n",
       "      <td>W286217</td>\n",
       "      <td>09-11-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382123</th>\n",
       "      <td>W286217</td>\n",
       "      <td>16-11-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382124</th>\n",
       "      <td>W286217</td>\n",
       "      <td>23-11-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382125</th>\n",
       "      <td>W286217</td>\n",
       "      <td>30-11-2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>625.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ItemId        Date  intake_cost  eoh_value\n",
       "62743    W286217  06-07-2022       625.41     625.41\n",
       "1382105  W286217  13-07-2022         0.00     625.41\n",
       "1382106  W286217  20-07-2022         0.00     625.41\n",
       "1382107  W286217  27-07-2022         0.00     625.41\n",
       "1382108  W286217  03-08-2022         0.00     625.41\n",
       "1382109  W286217  10-08-2022         0.00     625.41\n",
       "1382110  W286217  17-08-2022         0.00     625.41\n",
       "1382111  W286217  24-08-2022         0.00     625.41\n",
       "1382112  W286217  31-08-2022         0.00     625.41\n",
       "1382113  W286217  07-09-2022         0.00     625.41\n",
       "1382114  W286217  14-09-2022         0.00     625.41\n",
       "1382115  W286217  21-09-2022         0.00     625.41\n",
       "1382116  W286217  28-09-2022         0.00     625.41\n",
       "1382117  W286217  05-10-2022         0.00     625.41\n",
       "1382118  W286217  12-10-2022         0.00     625.41\n",
       "1382119  W286217  19-10-2022         0.00     625.41\n",
       "1382120  W286217  26-10-2022         0.00     625.41\n",
       "1382121  W286217  02-11-2022         0.00     625.41\n",
       "1382122  W286217  09-11-2022         0.00     625.41\n",
       "1382123  W286217  16-11-2022         0.00     625.41\n",
       "1382124  W286217  23-11-2022         0.00     625.41\n",
       "1382125  W286217  30-11-2022         0.00     625.41"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge stock value df with forecast and open po data\n",
    "merge_df = item_summary.merge(forecast_process,how='outer',on=['ItemId','Date'])\n",
    "merge_df = merge_df.merge(open_po,how='outer',on=['ItemId','Date'])\n",
    "#fill in empty value by = 0\n",
    "merge_df['Stock_value'].fillna(0,inplace=True)\n",
    "merge_df['forecast_per_week_processed'].fillna(0,inplace=True)\n",
    "merge_df['po_cost'].fillna(0,inplace=True)\n",
    "#calculate the intake value\n",
    "merge_df['intake_cost'] = merge_df.Stock_value - merge_df.forecast_per_week_processed + merge_df.po_cost\n",
    "\n",
    "#remove no SOH,noPO,no forecast item\n",
    "no_value_filter = merge_df.groupby('ItemId').sum()[['Stock_value','forecast_per_week_processed','po_cost','intake_cost']].reset_index()\n",
    "item_filter_list = no_value_filter.loc[(\n",
    "    no_value_filter.Stock_value==0)&(no_value_filter.forecast_per_week_processed==0)&(no_value_filter.po_cost==0),'ItemId']\n",
    "merge_df=merge_df.loc[~merge_df['ItemId'].isin(item_filter_list),:]\n",
    "#get needed data only\n",
    "merge_df =merge_df[['ItemId','Date','intake_cost']]\n",
    "\n",
    "#Calculate EOH stock value\n",
    "unique_items = merge_df['ItemId'].unique()\n",
    "for i in unique_items:\n",
    "    merge_df.loc[merge_df.ItemId == i,'eoh_value'] = merge_df.loc[merge_df.ItemId == i,'intake_cost'].cumsum()\n",
    "merge_df.loc[merge_df.ItemId=='W286217',:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:41: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "c:\\Users\\datqu\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\ipykernel_launcher.py:42: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "#create final dataframe\n",
    "projected_stock_value = merge_df.copy()\n",
    "projected_stock_value = projected_stock_value [['ItemId','Date','eoh_value']]\n",
    "\n",
    "#make format equal original dataframe format\n",
    "projected_stock_value.rename(columns={'eoh_value':'Stock_value'},inplace=True)     \n",
    "#exclude current date\n",
    "projected_stock_value = projected_stock_value.loc[projected_stock_value['Date']!=r0695_date,:]\n",
    "#create item attribute\n",
    "item_attribute = process_dataset.loc[process_dataset.Date == r0695_date,['ItemId','ItemGroup','CoverageGroup','Brand','BuyerCode',\n",
    "                                                                         'SuperGrpDesc',\n",
    "                                                                         'Std_cost_latest','Vendor','CoverageGroup1']]\n",
    "item_attribute.drop_duplicates(subset=['ItemId'],inplace=True)\n",
    "#extract history of stock to merge\n",
    "item_stock_hist = process_dataset[['ItemId','Date','Stock_value','Usage_3_Months_value','Forecast_3_months_value']]\n",
    "#concate projected data to current stock data\n",
    "projected_stock_value = pd.concat([item_stock_hist,projected_stock_value])\n",
    "#merge item attribute to get full table\n",
    "projected_stock_value = projected_stock_value.merge(item_attribute,on='ItemId',how='inner')\n",
    "#add additional column to determine current date\n",
    "projected_stock_value['Latest_data_date'] = r0695_date\n",
    "#generate is_today,lastmonth,lastyear\n",
    "last_month_date = curdate_datetime - timedelta(days=7*4)\n",
    "last_year_date = curdate_datetime - timedelta(days=7*52)\n",
    "last_month_date = last_month_date.strftime('%d-%m-%Y')\n",
    "last_year_date = last_year_date.strftime('%d-%m-%Y')\n",
    "projected_stock_value['is_today']='N'\n",
    "projected_stock_value.loc[projected_stock_value.Date==r0695_date,'is_today'] ='today'\n",
    "projected_stock_value.loc[projected_stock_value.Date==last_month_date,'is_today'] ='last_month_date'\n",
    "projected_stock_value.loc[projected_stock_value.Date==last_year_date,'is_today'] ='last_year_date'\n",
    "\n",
    "#flag slow moving stock if SOH >=7 month forcast or 7x month average usage\n",
    "#sum forecast\n",
    "slow_moving['fc'] = slow_moving.FC_CUR1 +slow_moving.Forecast_Current_plus_1+slow_moving.Forecast_Current_plus_2 +\\\n",
    "    slow_moving.Forecast_Current_plus_3+slow_moving.Forecast_Current_plus_4 +slow_moving.Forecast_Current_plus_5 +slow_moving.Forecast_Current_plus_6\n",
    "k = slow_moving[['ItemId','fc']]\n",
    "#merge\n",
    "slow_moving_df = item_summary.merge(k,on='ItemId',how='left')\n",
    "#convert to float\n",
    "slow_moving_df['AvgMthUsage'] = slow_moving_df['AvgMthUsage'].astype(str) #to be confirm\n",
    "slow_moving_df['AvgMthUsage']= slow_moving_df['AvgMthUsage'].str.replace('(','-')\n",
    "slow_moving_df['AvgMthUsage'] = slow_moving_df['AvgMthUsage'].str.replace(')','')\n",
    "slow_moving_df['AvgMthUsage'] =  slow_moving_df['AvgMthUsage'].str.replace(\",\",\"\").astype(float)\n",
    "#if no forecast us average usage\n",
    "\n",
    "slow_moving_df['fc'].fillna(slow_moving_df['AvgMthUsage']*7,inplace=True)\n",
    "slow_moving_df['slow_moving']=slow_moving_df.apply(lambda y: \"Normal stock\" if (y['SOH'] - y['fc']) <= 0 else \"Slow moving stock\",axis=1)\n",
    "slow_moving_df = slow_moving_df[['ItemId','slow_moving']]\n",
    "projected_stock_value =projected_stock_value.merge(slow_moving_df,on='ItemId',how='left')\n",
    "projected_stock_value.fillna(0,inplace=True)\n",
    "#save to csv\n",
    "projected_stock_value.to_csv('archive/summary_aggregate_item_projected.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('bootcamp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7c284f6c3454d9296f827a682b0575908dd97079acfefde70d6f996863eb3eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
